{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMP5046_Lab01.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3-tNXEbFOf-g",
        "lONWx3FtSwWJ",
        "7g3eNemEOklg",
        "I2cusD7IovCi",
        "P4rd7JPrr4sc",
        "rJfYbAtPrMNS"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinlu2/COMP5046/blob/main/Labs/COMP5046_Lab01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-tNXEbFOf-g"
      },
      "source": [
        "# Lab 01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vmb3ZK5SOhz"
      },
      "source": [
        "# PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jJgT_lITGdG"
      },
      "source": [
        "[PyTorch](https://pytorch.org/) is an open source machine learning library used for applications such as natural language processing and computer vision. It is based on the [Torch](http://torch.ch/) library.\n",
        "\n",
        "Before we use Pytorch it is (obviously) neccessary to understand what Pytorch is. Let's start from the two core concepts: **Tensor**, **(Computational) Graph** and **Automatic Differentiation**\n",
        "\n",
        "\n",
        "## Tensor\n",
        "A tensor is a generalization of vectors and matrices to potentially higher dimensions. It is the primary data structure used by neural networks. Normally, we can use **nd**-tensor to call any of its instances where **nd** stands for **n** **dimensional**.\n",
        "\n",
        "There are three basic attributes we need to know about tensors:\n",
        "*   *Rank*: The number of dimensions present within the tensor. e.g. rank-2 tensor means 2d-tensor.\n",
        "*   *Axes*: Used to refer to a specific dimensions. The number of axes equals to the number of dimensions. The length of an axis represents the number of elements running along this axis. \n",
        "*   *Shape*: Formed by the length of each axis. e.g. shape(1,2) means a 2d-tensor with the first axis of length 1 and the second axis of length 2. \n",
        "\n",
        "\n",
        "![Tensor_Rank](https://drive.google.com/uc?id=1o5wulLHGxUuPxH3t3xfV8U7d2CrsL1oG)\n",
        "\n",
        "\n",
        "A [torch.Tensor](https://pytorch.org/docs/stable/tensors.html) (tensor in PyTorch) has the following key properties : \n",
        "*   *torch.dtype*: an object representing the data type of a torch.Tensor. e.g. torch.float32\n",
        "*   *torch.device*: an object representing the device on which a torch.Tensor is or will be allocated. e.g. CPU or CUDA (GPU)\n",
        "*   *torch.layout*: an object representing the memory layout of a torch.Tensor.\n",
        "\n",
        "More details with illustrative examples can be found [here](https://pytorch.org/docs/stable/tensor_attributes.html#tensor-attributes-doc) \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lONWx3FtSwWJ"
      },
      "source": [
        "## Computational Graph and Automatic Differentiation\n",
        "PyTorch uses (directed acyclic) computational graphs  to graph the functional operations that are applied to tensors inside neural networks so as to computationally calculate derivatives for the network optimization. In graphs, the nodes are Tensors while the eages are functions that produce output Tensors from input Tensors (e.g. summation, mutiplication). Those graphs enable PyTorch to do the automatic differentiation for us, i.e. it can automatically calculate the derivatives that are needed for network optimization. We will learn more about it through pratical examples in following sections.\n",
        "\n",
        "Specifically, PyTorch generates the computational graph on the fly as when operations are created during forward passes in neural networks, which is refered as dynamic computational graph. This is the one of the main differences between PyTorch and TensorFlow which uses static computational graphs.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWQxFb_W8flk"
      },
      "source": [
        "## Importing PyTorch library\n",
        "[Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb) has torch library installed as default so you just need to import it as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "horLjqk6TNZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fbf2b6-69d6-488c-a317-77114b89108c"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__) #check version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPp2MGCe1apL"
      },
      "source": [
        "## Tensor creation\n",
        "With PyTorch, we will be implementing lots of models. To get started, let's  have a look at how to create a tensor.\n",
        "\n",
        "We can creating tensors **with numerical data**, typically numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSymfXYxUT-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63bc1693-7567-48b2-8bd5-9b9b6aebe5c4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Scalar (0 Rank)\n",
        "data = torch.tensor(1)\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "# Vector (1 Rank)\n",
        "data = np.array([1,2]) \n",
        "data = torch.Tensor(data)\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "# Matrix (2 Rank)\n",
        "data = np.ones((2,2,)) \n",
        "data = torch.Tensor(data)\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "# Cube (3 Rank)\n",
        "data = np.ones((2,2,2)) \n",
        "data = torch.Tensor(data)\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "# Vector of cubes (4 Rank)\n",
        "data = np.ones((2,2,2,2)) \n",
        "data = torch.Tensor(data)\n",
        "print(data.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([])\n",
            "torch.Size([2])\n",
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2, 2])\n",
            "torch.Size([2, 2, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LEAyEhrn03F"
      },
      "source": [
        "Notice that although both torch.Tensor() and torch.tensor() can be used to  generate tensors, there are some differences:\n",
        "\n",
        "*   uppercase T VS. lowercase t (obviously)\n",
        "*   torch.Tensor() is the constructor of the torch.Tensor class while the torch.tensor() is a factory function that constructs torch.Tensor objects and return them to the caller \n",
        "*   torch.Tensor() can return an empty tensor without specifying incoming data while torch.tensor() with no input data will prouduce a TypeError (you can try)\n",
        "*   torch.Tensor uses the default dtype \"float32\" while the torch.tensor() choose the same dtype based on the incoming data (type inference), this can be easily illustrated through following example:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxsULaaptyF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6929e233-eae4-4bdd-8b44-03e2cce19dd4"
      },
      "source": [
        "data = np.array([1,2]) \n",
        "print(data.dtype)\n",
        "\n",
        "data_T = torch.Tensor(data)\n",
        "print(data_T)\n",
        "print(data_T.dtype)\n",
        "print(data_T.dtype==torch.get_default_dtype()) #get the torch default data type, \n",
        "\n",
        "#which can also be changed through 'torch.set_default_dtype(dtype)'\n",
        "print()\n",
        "\n",
        "data_t = torch.tensor(data)\n",
        "print(data_t)\n",
        "print(data_t.dtype)\n",
        "print()\n",
        "\n",
        "#we can also specify a datatype with torch.tensor()\n",
        "data_t = torch.tensor(data, dtype=torch.float64)\n",
        "print(data_t)\n",
        "print(data_t.dtype)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int64\n",
            "tensor([1., 2.])\n",
            "torch.float32\n",
            "True\n",
            "\n",
            "tensor([1, 2])\n",
            "torch.int64\n",
            "\n",
            "tensor([1., 2.], dtype=torch.float64)\n",
            "torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE2tWt771BYk"
      },
      "source": [
        "Expect for torch.Tensor() and torch.tensor(), We can also use torch.as_tensor and torch.from_numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE5zySUlbYPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f389c5cf-2554-48e4-d6ab-e72b17a2bf45"
      },
      "source": [
        "# Create tensor using torch.as_tensor \n",
        "data = np.ones((2,2,2)) \n",
        "data = torch.as_tensor(data)\n",
        "print(data.shape)\n",
        "print(data.dtype)\n",
        "# Create tensor using torch.from_numpy\n",
        "data = np.ones((2,2,2,2))\n",
        "data = torch.from_numpy(data)\n",
        "print(data.shape)\n",
        "print(data.dtype)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 2])\n",
            "torch.float64\n",
            "torch.Size([2, 2, 2, 2])\n",
            "torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-hrVh5Eb50F"
      },
      "source": [
        "Alternatively, we can also create tensors **without data** using factory functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGnl32afcBnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2deb1e68-f5a1-4d4a-b2a8-984aeb5734ca"
      },
      "source": [
        "# torch.eye: Returns an identity matrix \n",
        "torch.eye(2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8QlyKrPcxs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1883694-4031-44a1-b2e9-0200e8a759c7"
      },
      "source": [
        "# torch.zeros: Returns a tensor of given shape filled with all zeros\n",
        "torch.zeros(2,2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO_IkTuSc66X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b26f9d9-ae72-4e8a-c18f-d7143bc8fe0e"
      },
      "source": [
        "# torch.ones: Returns a tensor of given shape filled with all ones\n",
        "torch.ones(2,2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZqJpoIXc8wL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8501cda3-d10f-4334-8a4e-9183350a381e"
      },
      "source": [
        "# torch.rand: Returns a tensor of given shape filled with values drawn from a uniform distribution on [0, 1).\n",
        "torch.rand(2,2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0242, 0.6785],\n",
              "        [0.3892, 0.4548]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTOQtikExO7M"
      },
      "source": [
        "More factory functions for tensor creation can be found [here](https://pytorch.org/cppdocs/notes/tensor_creation.html#factory-functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bff_DPKHbSvY"
      },
      "source": [
        "## Basic tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKz1UOFEHYVr"
      },
      "source": [
        "The list of operations with examples can be found [here](https://pytorch.org/docs/stable/torch.html#math-operations). Please go through and try to practise yourself with examples before you move on. You don't need to remember all of them, you can easily refer back when needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE91VTvN_YVB"
      },
      "source": [
        "## Simple Linear Regression\n",
        "\n",
        "![Linear_Regression](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/320px-Linear_regression.svg.png)\n",
        "\n",
        "The following code implements a simple linear regression algorithm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fXyR-6lGlie"
      },
      "source": [
        "### Linear Regression from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALnKOtUpGZyk"
      },
      "source": [
        "Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK900tGJBcbt"
      },
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# training data\n",
        "x_training = numpy.asarray([1,2,5,8,9,12,14,16,18,20])\n",
        "y_training = numpy.asarray([1500,3500,7200,11000,12500,18500,22000,24500,28000,30500])\n",
        "\n",
        "x_test = numpy.asarray([3,7,13,15,19])\n",
        "y_test = numpy.asarray([4400,10000,19500,23500,29000])\n",
        "\n",
        "# creating tensor for trainig from training data\n",
        "x_data = torch.from_numpy(x_training)\n",
        "y_data = torch.from_numpy(y_training)\n",
        "x_test_data = torch.from_numpy(x_test)\n",
        "y_test_data = torch.from_numpy(y_test)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4DA9NoJG10G"
      },
      "source": [
        " Once the dataset is prepared, we can start defining our model architecture\n",
        " \n",
        " Let's first build it from scratch so as to gain a clear understanding about how the automatic differentiation works\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzlkNOOpGk8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c272806-dc36-428b-af23-89ee58ad0d82"
      },
      "source": [
        "# Define weights and biases\n",
        "weight = torch.tensor(numpy.random.randn(), requires_grad=True)\n",
        "bias = torch.tensor(numpy.random.randn(), requires_grad=True)\n",
        "print(weight)\n",
        "print(bias)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6976, requires_grad=True)\n",
            "tensor(0.5427, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p3lWE7DL_c2"
      },
      "source": [
        "Note that we set 'requires_grad=True' above, which turns on the automatic gradient computation for weight and bias.\r\n",
        "\r\n",
        "Every Tensor has a flag: 'requires_grad' that allows for fine grained exclusion of subgraphs from gradient computation and can increase efficiency. If there’s a single input to an operation that requires gradient, its output will also require gradient. Conversely, only if all inputs don’t require gradient, the output also won’t require it. Backward computation is never performed in the subgraphs, where all Tensors didn’t require gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnGNiyccJEU7"
      },
      "source": [
        "# Define the model\n",
        "# Hypothesis = W * X + b (Linear Model)\n",
        "def linearRegression(x):\n",
        "  return x * weight + bias"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYVxYYEaJw_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5569e058-76ab-4b86-b3f2-5c31a293150f"
      },
      "source": [
        "# Generate predictions and compare with ground truth labels\n",
        "# As we can see, we randomly initialise the weight and bias, the model does not predict properly at the moment\n",
        "predictions = linearRegression(x_data)\n",
        "print(predictions)\n",
        "print(y_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1.2403,  1.9379,  4.0307,  6.1236,  6.8212,  8.9140, 10.3092, 11.7045,\n",
            "        13.0997, 14.4949], grad_fn=<AddBackward0>)\n",
            "tensor([ 1500,  3500,  7200, 11000, 12500, 18500, 22000, 24500, 28000, 30500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rjCmeI3KxEy"
      },
      "source": [
        "# Define loss function \n",
        "# here we use mean squared error (MSE)\n",
        "def mse(x1, x2):\n",
        "  diff = x1 - x2\n",
        "  return torch.sum(diff*diff)/diff.numel()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnnZ_W8yLPLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8a75d1-76a6-4c2e-d038-ead1c5131874"
      },
      "source": [
        "# Compute loss\n",
        "# As we all know, the lower, the better\n",
        "loss = mse(predictions, y_data)\n",
        "print(loss)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3.4810e+08, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua8D9hd2MmSb"
      },
      "source": [
        "As is mentioned, PyTorch automatically compute the gradient/derivative of the loss (with regard to the weight and bias here). This was enabled when we set 'requires_grad=True' to them.\n",
        "\n",
        "All we need to do now is to call the backward() over our loss, which will trigger the automatical computation of gradients based on the chain rule."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ5PL5rbNJ09"
      },
      "source": [
        "# Compute gradients\n",
        "loss.backward()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwuD_tYMNnZP"
      },
      "source": [
        "After the backward passing, the gradients are stored in the .grad property of the involved tensors. Let's have a look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5glqZhkN1Fl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6cd35a-6648-4399-b47c-2a35f3e6f4ca"
      },
      "source": [
        "# Gradient for weight\n",
        "print(weight)\n",
        "print(weight.grad)\n",
        "print()\n",
        "\n",
        "# Gradient for bias\n",
        "print(bias)\n",
        "print(bias.grad)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6976, requires_grad=True)\n",
            "tensor(-455980.0625)\n",
            "\n",
            "tensor(0.5427, requires_grad=True)\n",
            "tensor(-31824.2656)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvHjhErrPiDk"
      },
      "source": [
        "Now we can easily adjust the weight and bias using the gradients.\n",
        "\n",
        "We need to reset the gradients before the next forward pass, because PyTorch accumulates gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_HXZkOUP-vB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed31af7-a7f0-4f83-8b66-978d4fa034f4"
      },
      "source": [
        "# We do not want gradient for the update operation\n",
        "# There will not be automatic gradient computation within the torch.no_grad() \n",
        "# We use learning rate of 1e-5 here\n",
        "\n",
        "with torch.no_grad(): \n",
        "  weight -= weight.grad * 1e-5\n",
        "  bias -= bias * 1e-5\n",
        "  # remember to reset the gradients\n",
        "  weight.grad.zero_()\n",
        "  bias.grad.zero_()\n",
        "print(weight)\n",
        "print(bias)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5.2574, requires_grad=True)\n",
            "tensor(0.5427, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSj4yiSSSOJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b9d083-1fda-4c63-ddb7-543251b36575"
      },
      "source": [
        "print(weight.grad)\n",
        "print(bias.grad)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.)\n",
            "tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rmo63CASlPp"
      },
      "source": [
        "Let's predict and compute loss again. The loss should be lower with new weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRBatrmLSxmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e8ffbc-f89d-40c7-ea09-8b9670ea6ca9"
      },
      "source": [
        "predictions = linearRegression(x_data)\n",
        "loss = mse(predictions, y_data)\n",
        "print(loss)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3.4602e+08, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE05OxGETIGd"
      },
      "source": [
        "Hope you now have an initial clear understanding of how automatic gradient computing works.\n",
        "\n",
        "Let's start training the model for multiple epochs.\n",
        "\n",
        "We can just simply create python loop to do it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glakWvo4TmmU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88731285-322f-46ba-c68a-32bca93ed4f6"
      },
      "source": [
        "# An epoch is one iteration over the entire input data\n",
        "no_of_epochs = 5000\n",
        "# How often you want to display training info.\n",
        "display_interval = 200\n",
        "\n",
        "for epoch in range(no_of_epochs):\n",
        "  predictions = linearRegression(x_data)\n",
        "  loss = mse(predictions, y_data)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    weight -= weight.grad * 1e-5\n",
        "    bias -= bias.grad * 1e-5\n",
        "    weight.grad.zero_()\n",
        "    bias.grad.zero_()\n",
        "  if epoch % display_interval == 0 :\n",
        "      # calculate the cost of the current model\n",
        "      predictions = linearRegression(x_data)\n",
        "      loss = mse(predictions, y_data)           \n",
        "      print(\"Epoch:\", '%04d' %(epoch), \"loss=\", \"{:.8f}\".format(loss), \"W=\", \"{:.4f}\".format(weight), \"b=\",  \"{:.4f}\".format(bias))\n",
        "\n",
        "print(\"=========================================================\")\n",
        "training_loss = mse(linearRegression(x_data), y_data)   \n",
        "print(\"Optimised:\", \"loss=\", \"{:.9f}\".format(training_loss.data), \\\n",
        "              \"W=\", \"{:.9f}\".format(weight.data), \"b=\", \"{:.9f}\".format(bias.data))\n",
        "    \n",
        "# Plot training data on the graph\n",
        "plt.plot(x_training, y_training, 'ro', label='Training data')\n",
        "plt.plot(x_training, weight.data * x_training + bias.data, label='Linear')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Calculate testing loss\n",
        "testing_loss = mse(linearRegression(x_test_data), y_test_data) \n",
        "print(\"Testing loss=\", \"{:.9f}\".format(testing_loss.data))\n",
        "print(\"Absolute mean square loss difference:\", \"{:.9f}\".format(abs(\n",
        "      training_loss.data - testing_loss.data)))\n",
        "  \n",
        "# Plot testing data on the graph\n",
        "plt.plot(x_test, y_test, 'bo', label='Testing data')\n",
        "plt.plot(x_test, weight.data * x_test + bias.data, label='Linear')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0000 loss= 343948800.00000000 W= 9.8036 b= 0.8600\n",
            "Epoch: 0200 loss= 103514656.00000000 W= 691.9388 b= 48.3393\n",
            "Epoch: 0400 loss= 31366064.00000000 W= 1065.6230 b= 74.1174\n",
            "Epoch: 0600 loss= 9715916.00000000 W= 1270.3403 b= 88.0082\n",
            "Epoch: 0800 loss= 3219094.50000000 W= 1382.4998 b= 95.3872\n",
            "Epoch: 1000 loss= 1269483.00000000 W= 1443.9554 b= 99.1995\n",
            "Epoch: 1200 loss= 684354.56250000 W= 1477.6370 b= 101.0582\n",
            "Epoch: 1400 loss= 508681.50000000 W= 1496.1038 b= 101.8468\n",
            "Epoch: 1600 loss= 455881.18750000 W= 1506.2352 b= 102.0497\n",
            "Epoch: 1800 loss= 439945.65625000 W= 1511.8014 b= 101.9319\n",
            "Epoch: 2000 loss= 435074.18750000 W= 1514.8662 b= 101.6387\n",
            "Epoch: 2200 loss= 433522.06250000 W= 1516.5616 b= 101.2496\n",
            "Epoch: 2400 loss= 432966.59375000 W= 1517.5063 b= 100.8083\n",
            "Epoch: 2600 loss= 432710.84375000 W= 1518.0399 b= 100.3385\n",
            "Epoch: 2800 loss= 432544.34375000 W= 1518.3483 b= 99.8534\n",
            "Epoch: 3000 loss= 432405.56250000 W= 1518.5323 b= 99.3602\n",
            "Epoch: 3200 loss= 432274.31250000 W= 1518.6490 b= 98.8627\n",
            "Epoch: 3400 loss= 432146.50000000 W= 1518.7290 b= 98.3633\n",
            "Epoch: 3600 loss= 432019.68750000 W= 1518.7863 b= 97.8628\n",
            "Epoch: 3800 loss= 431892.81250000 W= 1518.8351 b= 97.3623\n",
            "Epoch: 4000 loss= 431767.15625000 W= 1518.8839 b= 96.8618\n",
            "Epoch: 4200 loss= 431640.93750000 W= 1518.9235 b= 96.3613\n",
            "Epoch: 4400 loss= 431515.31250000 W= 1518.9586 b= 95.8609\n",
            "Epoch: 4600 loss= 431390.15625000 W= 1518.9935 b= 95.3620\n",
            "Epoch: 4800 loss= 431264.68750000 W= 1519.0287 b= 94.8630\n",
            "=========================================================\n",
            "Optimised: loss= 431140.593750000 W= 1519.063476562 b= 94.366722107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxVdf7H8dcHxAVwAXdZxH3FFZe0RctcK1Or0Zi01Wxqmmpm1CQnK/mlTWONjdnYtFhDWeOSWppLaZqNaxmLG6iAIIIroMj+/f1xD85VQVDgXpbP8/Hgce/9nu+593Mvl/PmbN8jxhiUUkpVby7OLkAppZTzaRgopZTSMFBKKaVhoJRSCg0DpZRSQA1nF3CjGjVqZAICApxdhlJKVSp79uw5ZYxpfGV7pQ2DgIAAdu/e7ewylFKqUhGRuMLadTORUkopDQOllFIaBkoppajE+wwKk5OTQ0JCApmZmc4uRQG1a9fG19cXNzc3Z5eilCpGlQqDhIQE6tatS0BAACLi7HKqNWMMp0+fJiEhgVatWjm7HKVUMarUZqLMzEwaNmyoQVABiAgNGzbUtTSlykpYGAQEgIuL7TYsrEyfvkqtGQAaBBWI/i6UKiNhYTB5MmRk2B7HxdkeAwQHl8lLVKk1A6WUqpJCQiAjg7O167K8y2BbW0aGrb2MFBsGIlJbRHaKyK8iEiUir1jtrURkh4jEiMgXIlLTaq9lPY6xpgfYPdeLVvtBERlm1z7caosRkell9u4c7PTp0/To0YMePXrQrFkzfHx8Lj3Ozs6+5ry7d+/m2WefLfY1BgwYUFblXmbQoEHFnsT39ttvk1Hwn4lSymFMfDyrO97CkMcXMm3Esxyv28g2IT6+zF6jJGsGWcDtxpjuQA9guIj0B+YCbxlj2gJngces/o8BZ632t6x+iEhnYDzQBRgOvCsiriLiCiwARgCdgQlW3/JXxtvgGjZsyN69e9m7dy9Tpkzh+eefv/S4Zs2a5ObmFjlvUFAQ8+fPL/Y1fvrpp1LVWBoaBko53onUTJ54MJTfj55Gi7STrFz8Ai3ST9km+vuX2esUGwbG5rz10M36McDtwFKrfTFwr3V/tPUYa/odYtt4PBpYYozJMsYcBWKAvtZPjDHmiDEmG1hi9S1fBdvg4uLAmP9tgyvjnTIPP/wwU6ZMoV+/fkydOpWdO3dy00030bNnTwYMGMDBgwcB2Lx5M3fddRcAs2bN4tFHH2XQoEG0bt36spDw9PS81H/QoEHcd999dOzYkeDgYAquWrdmzRo6duxI7969efbZZy89r72LFy8yfvx4OnXqxJgxY7h48eKlaU899RRBQUF06dKFl19+GYD58+dz/PhxBg8ezODBg4vsp5QqG/n5hs92xHPnvB/Y6hfIjB8/ZcWnf6TzyaO2Du7uEBpaZq9Xoh3I1n/ve4C22P6LPwycM8YU/KubAPhY932AYwDGmFwRSQUaWu3b7Z7Wfp5jV7T3u+53cr2sbXCXKdgGV0Y7ZAokJCTw008/4erqSlpaGlu3bqVGjRps3LiRGTNmsGzZsqvmOXDgAJs2bSI9PZ0OHTrw1FNPXXW8/i+//EJUVBQtWrRg4MCBbNu2jaCgIJ588km2bNlCq1atmDBhQqE1LVy4EHd3d/bv3094eDi9evW6NC00NBRvb2/y8vK44447CA8P59lnn2XevHls2rSJRo0aFdmvW7duZfjJKVU9HT11genLwtlx9Az9W3szZ2w3ArqmQsJ226Yhf39bEJThsqpEYWCMyQN6iEgDYAXQscwquA4iMhmYDOBf2tWjora1leE2uAL3338/rq6uAKSmpjJp0iSio6MREXJycgqdZ9SoUdSqVYtatWrRpEkTkpOT8fX1vaxP3759L7X16NGD2NhYPD09ad269aVj+ydMmMCiRYuuev4tW7Zc2kfRrVu3yxbiX375JYsWLSI3N5ekpCT27dtX6EK+pP2UUiWTm5fPv348ylsbDlHT1YXXxwYyvo+f7ci84OAy/0fV3nUdWmqMOScim4CbgAYiUsNaO/AFEq1uiYAfkCAiNYD6wGm79gL28xTVfuXrLwIWAQQFBZnrqf0q/v62TUOFtZcxDw+PS/dnzpzJ4MGDWbFiBbGxsQwaNKjQeWrVqnXpvqura6H7G0rS53odPXqUN998k127duHl5cXDDz9c6LkCJe2nlCqZqOOpTFsWTmRiGnd2bspro7vSrH5th71+SY4mamytESAidYA7gf3AJuA+q9skYKV1f5X1GGv698a2MXsVMN462qgV0A7YCewC2llHJ9XEtpN5VVm8uWsKDbVtc7NXxtvgCpOamoqPj23r2Mcff1zmz9+hQweOHDlCbGwsAF988UWh/W699VY+++wzACIjIwkPDwcgLS0NDw8P6tevT3JyMmvXrr00T926dUlPTy+2n1Kq5DJz8vjrugPc849tnEjNZMGDvVj0UG+HBgGUbM2gObDY2m/gAnxpjPlaRPYBS0RkNvAL8IHV/wPgUxGJAc5gW7hjjIkSkS+BfUAu8LS1+QkReQZYB7gCHxpjosrsHRalYHUrJKTctsEVZurUqUyaNInZs2czatSoMn/+OnXq8O677zJ8+HA8PDzo06dPof2eeuopHnnkETp16kSnTp3o3bs3AN27d6dnz5507NgRPz8/Bg4ceGmeyZMnM3z4cFq0aMGmTZuK7KeUKpldsWeYtiycIycvMK6XLy+N6oSXR02n1CIFR6BUNkFBQebK4+L3799Pp06dnFRRxXH+/Hk8PT0xxvD000/Trl07nn/+eafUor8Tpa6WnpnDG98e5NPtcfg0qMP/jQ3ktvZXXXysXIjIHmNM0JXtVW44CgXvv/8+ixcvJjs7m549e/Lkk086uySllGXTgRRCVkSQlJbJwwMC+POwDnjUcv6i2PkVqDL3/PPPO21NQClVuDMXsnl1dRRf7T1O2yaeLJ0ygN4tvZxd1iUaBkopVY6MMaz69TivrN5H2sUcnr2jHU8PbkOtGq7OLu0yGgZKKVVOjp+7yEtfRfL9gRS6+9Zn7hP96NisnrPLKpSGgVJKlbH8fEPYznjmrj1Abn4+L43qxCMDW+HqUnGHddchrJVSqiRKOLDlkZPnGb9oOzO/iqSbb33WP3cbj9/SukIHAeiaQZnz9PTk/Pnzl7W99957uLu7M3HiRCdVpZQqlRJcXCYnL5/3tx7h7Y3R1KrhwhvjunF/kG+luciThoEDTJkypVyf3xiDMQYXF13RU6pcFDOwZWRiKlOXhrMvKY3hXZrx6uguNKnn2DOIS0uXHg4wa9Ys3nzzTcB2EZlp06bRt29f2rdvz9atWwHIy8vjz3/+M3369KFbt27885//BGwnkN1xxx306tWLwMBAVq60jfoRGxtLhw4dmDhxIl27duXYsWOFv7hSqvSKGMAy8/gJ5qw9wOgF20hJz2JhcC/ee6h3pQsCqMJrBq+sjmLf8bQyfc7OLerx8t1dSv08ubm57Ny5kzVr1vDKK6+wceNGPvjgA+rXr8+uXbvIyspi4MCBDB06FD8/P1asWEG9evU4deoU/fv355577gEgOjqaxYsX079//1LXpJS6hkIGttzh24Xpd7/A0R8O80CQLyEjO1Pf3a2IJ6j4qmwYVGRjx44FoHfv3pcGlFu/fj3h4eEsXWq7XlBqairR0dH4+voyY8YMtmzZgouLC4mJiSQnJwPQsmVLDQKlHCE09NI+g/SadZgz6BHCeo7Ezy2Pf0/sx83tGjm7wlKrsmFQFv/Bl5eCoafth502xvDOO+8wbNiwy/p+/PHHnDx5kj179uDm5kZAQMCloaLth8ZWSpUjayfxdws+J6Tn/aR4ePNYw0z++IfRuNesGovRqvEuqoBhw4axcOFCbr/9dtzc3Dh06BA+Pj6kpqbSpEkT3Nzc2LRpE3GFXYNBKVWuTp3P4hWXzqy+9SnaN/Vk4bhu9PSvOENJlAUNgzKWkZFx2RXJXnjhhRLN9/jjjxMbG0uvXr0wxtC4cWO++uorgoODufvuuwkMDCQoKIiOHZ1ykTmlqiVjDF/tTeTV1fs4n5XL80Pa89SgNtSsUfWOvdEhrFW50t+JqqwSz10kZEUEmw+epKd/A+aO60b7pnWdXVap6RDWSilVAvn5hn/viGPu2gPkG3j57s5MvCmgwp9BXFoaBkopZYlJOc/0ZeHsjjvLLe0a8X9jAvHzdi9+xiqgyoWBMabSnP5d1VXWTZCq+snJy+efPxxm/ncx1Knpypv3d2dcL59qtSypUmFQu3ZtTp8+TcOGDavVL7EiMsZw+vRpateufGdiquolPOEcU5eGc+BEOqMCmzPrni40rlvL2WU5XJUKA19fXxISEjh58qSzS1HYwtn+yCqlKpKL2Xm8vfEQ7289QiPPWvzzod4M69LM2WU5TZUKAzc3N1q1auXsMpRSFdxPh0/x4vII4k5nMKGvH9NHdKJ+nco7lERZqFJhoJRS15J6MYc5a/fz+c5jtGzozmdP9GNAm8o/lERZ0DBQSlUL66NOMHNlJCfTs5h8a2ueH9KeOjUr1nWInUnDQClVpZ1Mz2LW6ii+CU+iY7O6vD8xiG6+DZxdVoWjYaCUqpKMMSz/OZFXv97Hxew8/jS0PU/e1gY316o3lERZ0DBQSlU5x85kMGNFBFujTxHU0os547rRtomns8uq0IqNSBHxE5FNIrJPRKJE5A9W+ywRSRSRvdbPSLt5XhSRGBE5KCLD7NqHW20xIjLdrr2ViOyw2r8QkZpl/UaVUlVfXr7ho21HGfb2Fn6OO8uro7vw5ZM3aRCUQEnWDHKBPxpjfhaRusAeEdlgTXvLGPOmfWcR6QyMB7oALYCNItLemrwAuBNIAHaJyCpjzD5grvVcS0TkPeAxYGFp35xSqvqITk5n6rJwfok/x6AOjQkdE4hPgzrOLqvSKDYMjDFJQJJ1P11E9gM+15hlNLDEGJMFHBWRGKCvNS3GGHMEQESWAKOt57sdeNDqsxiYhYaBUqoEsnPzWbj5MP/YFI1nrRq89Zvu3Nujeg0lURaua0+KiAQAPYEdVtMzIhIuIh+KSMGVHnwA+6uzJ1htRbU3BM4ZY3KvaC/s9SeLyG4R2a1nGStVzYSFQUAAuLjYbsPC2HvsHHe/8yNvbTzE8K7N2fDCbYzp6atBcANKHAYi4gksA54zxqRh+8+9DdAD25rD38qlQjvGmEXGmCBjTFDjxo3L++WUUhVFWJjtGsRxcWAMGcdP8NonPzJ2wY+kXszhXxODeGdCTxp5Vr8xhcpKiY4mEhE3bEEQZoxZDmCMSbab/j7wtfUwEfCzm93XaqOI9tNAAxGpYa0d2PdXSikICYGMDAC2tezO9OG/51iDZgRHb2Va2GvUq129h5IoCyU5mkiAD4D9xph5du3N7bqNASKt+6uA8SJSS0RaAe2AncAuoJ115FBNbDuZVxnbOMebgPus+ScBK0v3tpRSVUp8PKm1PJg64lmCx4dSIz+PJZ9NJ3TFGxoEZaQkawYDgYeACBHZa7XNACaISA/AALHAkwDGmCgR+RLYh+1IpKeNMXkAIvIMsA5wBT40xkRZzzcNWCIis4FfsIWPUkoB8O2Au5nZ4z7OuNdnyvb/8Ny2z6mdmw0tWzq7tCqjSl0DWSlVtaSkZfKXlVF8G3WCLilHmPvN23RNOWKb6O4OixZBcLBzi6xk9BrISqlKwxjDf3YnMPubfWTm5jNteEceTziH2/d5IAL+/hAaqkFQhjQMlFIVSvxp21ASP8acom8rb+aMDaR1Y0+gDfxWF/7lRcNAKVUhFAwl8bf1h3B1EWbf25UH+/rj4qLnDDiChoFSyukOnrANJfHrsXPc0bEJs8d0pXl9HUrCkTQMlFJOk5Wbx4JNh1m4OYa6td2YP6End3drrmcQO4GGgVLKKX6OP8u0peFEp5xnTE8fZt7VGW8PHbDYWTQMlFIOdSErlzfXH+Tjn2JpXq82Hz3Sh8Edmji7rGpPw0Ap5TBbDp3kxeURJJ67yMSbWjJ1eEc8a+liqCLQ34JSqtydy8jmta/3s+znBNo09mDplJsICvB2dlnKjoaBUqrcGGNYE3GCl1dFci4jh2cGt+WZ29tS283V2aWpK2gYKKXKRXJaJjO/imT9vmQCferzyaP96NyinrPLUkW4rovbKKWqsUIuLlMYYwxLdsYzZN4P/HDoJDNGdmTF7wZoEFRwumaglCpewcVlrGsKEBdnewyXjQ8Ue+oCLy6P4L9HTtO/tTdzxnYjoJGHEwpW10tHLVVKFS8gwBYAV2rZEmJjyc3L58NtR5m34RBuLi7MGNWJ8X389OSxCkhHLVVK3bj4+CLb9yelMW1ZOOEJqdzZuSmvje5Ks/q1HVufKjUNA6VU8fz9r1ozyHR14x8jJvPeOz/SwN2NBQ/2YmRgM10bqKQ0DJRSxQsNvWyfwW6fTkwb+QcOe/syrocPL43qhJcOJVGpaRgopYpn7SQ+//Kr/LXVYD7pNYoWNWHxQ325rX1jJxenyoKGgVKqRDYF3UnIY81ISsvk4QEB/GloBzx0KIkqQ3+TSqlrOnMhm9e+3seKXxJp18STpVMG0Lull7PLUmVMw0ApVShjDKvDk3hlVRRpmTn84Y52/G5wG2rV0KEkqiINA6XUVZJSL/LSiki+O5BCd78GvDGuGx2a1XV2WaocaRgopS7Jzzd8tjOeOWsPkJdveGlUJx4Z2ApXvQ5xladhoJQC4MjJ80xfHsHOo2cY2LYhr4/phn9Dd2eXpRxEw0Cpai43L5/3tx7lrY2HqF3DhTfu68b9vX315LFqpthRS0XET0Q2icg+EYkSkT9Y7d4iskFEoq1bL6tdRGS+iMSISLiI9LJ7rklW/2gRmWTX3ltEIqx55ot+C5VyiMjEVEYv2Mbcbw9wR8cmbHzhNh4I0jGFqqOSDGGdC/zRGNMZ6A88LSKdgenAd8aYdsB31mOAEUA762cysBBs4QG8DPQD+gIvFwSI1ecJu/mGl/6tKaWKkpmTx9xvDzB6wTZS0rN477e9WPjb3jSpp2MKVVfFbiYyxiQBSdb9dBHZD/gAo4FBVrfFwGZgmtX+ibENh7pdRBqISHOr7wZjzBkAEdkADBeRzUA9Y8x2q/0T4F5gbdm8RaWUvR1HTjN9eQRHT13ggSBfQkZ2pr67m7PLUk52XfsMRCQA6AnsAJpaQQFwAmhq3fcBjtnNlmC1Xas9oZD2wl5/Mra1Dfz9/a+ndKWqvfTMHOasPUDYjnj8vOvw78f6cXO7Rs4uS1UQJQ4DEfEElgHPGWPS7LcpGmOMiJT7hRGMMYuARWC7nkF5v55SVcV3+5N56atIktMyefzmVrwwtD3uNfX4EfU/Jfo2iIgbtiAIM8Yst5qTRaS5MSbJ2gyUYrUnAn52s/tabYn8b7NSQftmq923kP5KqVI6fT6LV1bvY9Wvx+nQtC4Lf9ubHn4NnF2WqoBKcjSRAB8A+40x8+wmrQIKjgiaBKy0a59oHVXUH0i1NietA4aKiJe143gosM6aliYi/a3Xmmj3XEqpG2CM4atfEhky7wfWRibx/JD2rP79zRoEqkglWTMYCDwERIjIXqttBjAH+FJEHgPigAesaWuAkUAMkAE8AmCMOSMirwG7rH6vFuxMBn4HfAzUwbbjWHceK3WDEs9dJGRFBJsPnqSnfwPmjutG+6Y6lIS6Nr0GslJVRH6+4d874pi79gD5BqYO78DEmwJ0KAl1Gb0GslJVWEzKeV5cHs6u2LPc0q4R/zcmED9vHUpClVxJTjpTSlUEYWEQEAAuLrbbsDBy8vJZsCmGkX/fyqHk87x5f3c+ebSvBoG6brpmoFRlEBZ22TWIiYsjIuR1pkbXZX+mK6MCmzPrni40rlvLuXWqSkvDQKnKICTkUhBcrFGLt29+kPf73Eujs+n8c/IdDOvSzMkFqspOw0CpyiA+HoD/+gUyfcTvifNqwYS93zL9h4+p//d0JxenqgINA6UqgdQ2HZjTZgif9xhOy7PH+ezzFxkQHwEtWzq7NFVFaBgoVcGtjzrBzN+8wclsmLxjGc//+Bl1crPA3R1CQ51dnqoiNAyUqqBOpmcxa3UU34Qn0bFZfd73OE63L7+HvGzbGkFoKAQHO7tMVUVoGChVwRhjWP5zIq9+vY+L2Xn8aWh7nrytDW6uLvDEeGeXp6ooDQOlKpBjZzKYsSKCrdGn6N3Si7njAmnbRIeSUOVPw0CpCiAv3/DJf2P567qDCPDKPV14qH9LXHQoCeUgGgZKOVl0cjpTl4XzS/w5bmvfmNAxXfH10jOIlWNpGCjlJNm5+SzcfJgFm2LwqOXKW7/pzr09fPRi9MopNAyUcoK9x84xbWk4B5PTubt7C16+uzONPHUoCeU8GgZKOVBGdi7z1h/iw21HaVK3Nv+aGMSQzk2Ln1GpcqZhoJSDbIs5xfTl4Rw7c5Hgfv5MG9GRerXdnF2WUoCGgVLlLjUjh9A1+/hydwKtGnmwZHJ/+rdu6OyylLqMhoFS5ejbyCRmrozizIVsptzWhueGtKO2m6uzy1LqKhoGSpWDlPRMXl4ZxdrIE3RuXo+PHu5DV5/6zi5LqSJpGChVhowx/GdPArO/3kdmbj5Th3fgiVta24aSUKoC0zBQqozEn7YNJfFjzCn6Bnjz+rhA2jT2dHZZSpWIhoFSpZSXb/ho21H+tv4Qri7C7Hu78mBffx1KQlUqGgZKlcLBE+lMWxbO3mPnuL1jE2bf25UWDeo4uyylrpuGgVI3ICs3j3c3HebdzTHUre3G38f34J7uLXQoCVVpaRgodZ1+jj/LtKXhRKec594eLfjL3V3w9qjp7LKUKpViD3EQkQ9FJEVEIu3aZolIoojstX5G2k17UURiROSgiAyzax9utcWIyHS79lYissNq/0JE9K9KVUgXsnJ5ZXUU4xb+xIWsXD56uA9vj++pQaCqhJIc7/YxMLyQ9reMMT2snzUAItIZGA90seZ5V0RcRcQVWACMADoDE6y+AHOt52oLnAUeK80bUqo8bI0+ybC3t/DRtlge6t+S9S/cxuCOTZxdllJlptjNRMaYLSISUMLnGw0sMcZkAUdFJAboa02LMcYcARCRJcBoEdkP3A48aPVZDMwCFpb0DShVns5lZDP7m/0s3ZNA68Ye/GfKTfQJ8HZ2WUqVudLsM3hGRCYCu4E/GmPOAj7Adrs+CVYbwLEr2vsBDYFzxpjcQvpfRUQmA5MB/P39S1G6UtdmjGFt5An+sjKKcxnZPDO4Lc/c3laHklBV1o2eFrkQaAP0AJKAv5VZRddgjFlkjAkyxgQ1btzYES+pqqHktEye/HQPvwv7meb1a7PqmZv507AOGgSqSruhNQNjTHLBfRF5H/jaepgI+Nl19bXaKKL9NNBARGpYawf2/ZVyKGMMX+w6Ruia/WTn5vPiiI48dnMrauhQEqoauKEwEJHmxpgk6+EYoOBIo1XAZyIyD2gBtAN2AgK0E5FW2Bb244EHjTFGRDYB9wFLgEnAyht9M0rdqLjTF3hxeQQ/HT5N/9bezBnbjYBGHs4uSymHKTYMRORzYBDQSEQSgJeBQSLSAzBALPAkgDEmSkS+BPYBucDTxpg863meAdYBrsCHxpgo6yWmAUtEZDbwC/BBmb07pYqRm5fPR9ti+duGg7i5uPD62EB+E+SnQ0moakeMMc6u4YYEBQWZ3bt3O7sMVYntT0pj2rJwwhNSGdKpKbPv7Uqz+rWdXZZS5UpE9hhjgq5s1zOQVbWTlZvHP76PYeHmwzRwd+MfD/ZkVGBzHUpCVWsaBqpa2RN3hmnLIohJOc/YXj7MHNUZLz2DWCkNA1U9nM/K5a/fHuCT7XG0qF+HxY/25bb2eniyUgU0DFSVt/lgCiErIjmeepFJNwXw52Ed8KilX32l7OlfhKqyzl7I5rWv97H8l0TaNvFk6ZQB9G7p5eyylKqQNAxUlWOM4evwJGatiiL1Yg7P3t6Wp29vS60aegaxUkXRMFBVSlLqRWZ+FcnG/Sl0963Pvx/vR6fm9ZxdllIVnoaBqhLy8w2f74pnzpoD5OTn89KoTjwysBWuevKYUiWig66oSu/IyfNMeH87ISsiCfStz7rnbuXxW1pfHQRhYRAQAC4uttuwMGeUq1SFpGsGqtLKzcvn/a1HeWvjIWrVcGHuuEAeCPIr/OSxsDCYPBkyMmyP4+JsjwGCgx1XtFIVlA5HoSqlyMRUpi0LJ+p4GsO6NOXV0V1pWu8aQ0kEBNgC4EotW0JsbHmVqVSFo8NRqCohMyePv38XzaItR/Byr8nC4F6MCGxe/Izx8dfXrlQ1o2GgKo2dR88wfVk4R05d4P7evoSM6kQD9xIOJeHvX/iagV4xTylAw0BVAumZOcz99gD/3h6Pr1cdPn2sL7e0u86hJEJDL99nAODubmtXSmkYqIrt+wPJhKyI5ERaJo8ObMWfhrXHveYNfG0LdhKHhNg2Dfn724JAdx4rBWgYqArq9PksXlm9j1W/Hqd9U08WBA+gl38ph5IIDtaFv1JF0DBQFYoxhpV7j/PK6ijOZ+Xy3JB2/G5QW2rW0FNilCpPGgaqwjh+7iIhKyLYdPAkPfwa8MZ93WjftK6zy1KqWtB/t5TT5ecbPv1vLHfO+4HtR84w867OLHtqwNVBoGcQK1VudM1AOdXhk+eZviycXbFnubltI14fG4ift/vVHfUMYqXKlZ6BrJwiJy+fRVuO8Pfvoqldw4WZd3Xmvt6+RV+HWM8gVqpM6BnIqsKISEhl6rJw9ielMTKwGbPu6UKTutcYSgL0DGKlypmGgXKYzJw83tp4iH9tPYq3R03e+21vhndtVrKZ9QxipcqVhoFyiP8ePs2Ly8OJPZ3Bb4L8mDGyE/Xd3Ur+BHoGsVLlSsNAlau0zBxeX3OAz3fG4+/tTtjj/RjYttH1P5GeQaxUuSr20FIR+VBEUkQk0q7NW0Q2iEi0detltYuIzBeRGBEJF5FedvNMsvpHi8gku/beIhJhzTNfityDqCqbDfuSuXPeD3yxK54nbmnFuuduvbEgKBAcbNtZnJ9vu9UgUKrMlOQ8g4+B4Ve0TQe+M8a0A76zHgOMANpZP5OBhWALD+BloB/QF3i5IECsPvwFNhEAAA9nSURBVE/YzXfla6lK5tT5LJ757Gee+GQ3Xu41WfG7gYSM6kydmnpBeqUqqmI3ExljtohIwBXNo4FB1v3FwGZgmtX+ibEdr7pdRBqISHOr7wZjzBkAEdkADBeRzUA9Y8x2q/0T4F5gbWnelHIOYwwrfknk1a/3kZGVxx/vbM+Tt7XRoSSUqgRudJ9BU2NMknX/BNDUuu8DHLPrl2C1Xas9oZD2QonIZGxrHPjrUSQVSsLZDGasiGTLoZP0bunF3HGBtG2iQ0koVVmUegeyMcaIiEPOXDPGLAIWge2kM0e8prq2PGsoiTfWHQTglXu68FD/lrhceTF6pVSFdqNhkCwizY0xSdZmoBSrPRHws+vna7Ul8r/NSgXtm61230L6q0ogOjmdacvC+Tn+HLe1b0zomK74ehUylIRSqsK70Y25q4CCI4ImASvt2idaRxX1B1KtzUnrgKEi4mXtOB4KrLOmpYlIf+soool2z6UqqOzcfOZ/F82o+T9y5NQF5j3QnY8f6aNBoFQlVuyagYh8ju2/+kYikoDtqKA5wJci8hgQBzxgdV8DjARigAzgEQBjzBkReQ3YZfV7tWBnMvA7bEcs1cG241h3Hldgvx47x7Rl4Rw4kc5d3Zoz654uNPKs5eyylFKlpAPVqRK5mJ3HvA0H+eDHozSuW4vZ9wZyZ+emxc+olKpQdKA6dcN+ijnF9OURxJ/J4MF+/kwf0ZF6ta9jKAmlVIWnYaCKlHoxh//7Zj9f7D5GQEN3lkzuT//WDZ1dllKqHGgYqEJ9G3mCv6yM5PSFbJ68rTXPD2lPbTc9g1ipqkrDQF0mJT2TWauiWBNxgk7N6/HBpD4E+tZ3dllKqXKmYaAA21ASS/ckMPub/VzMyePPwzow+dbWuLnqUBJKVQcaBopjZzKYsSKCrdGn6BPgxZxx3WjT2NPZZSmlHEjDoBrLyzd8/FMsb647iIvAa6O7ENxPh5JQqjrSMKimDiWnM3VpOHuPnWNwh8bMHhOIT4M6zi5LKeUkGgbVTHZuPu9ujmHBphjq1nbj7+N7cE/3Fug1hZSq3jQMqpFf4s8ybVk4h5LPM7pHC/5yV2ca6lASSik0DKqFjOxc3lx3iI+2HaFZxjk+XDOf25ekQJ5eQ1gpZaNhUMX9GH2K6cvDSTh7kYfC1zP1u39RN/uibeLkybZbDQSlqj0NgyoqNSOH2d/s4z97EmjdyIMvv5tH393fX94pIwNCQjQMlFIaBlXR2ogkZq6M4mxGNr8b1IZn72hH7ambCu8cH+/Y4pRSFZKGQRWSkpbJzJWRrItKpqtPPRY/2ocuLayhJPz9IS7u6pn0WtJKKTQMqgRjDF/uPsbsb/aTnZvP9BEdefzmVtSwH0oiNNS2jyAj439t7u62dqVUtadhUMnFnb7Ai8sj+Onwafq18mbOuG60auRxdceC/QIhIbZNQ/7+tiDQ/QVKKTQMKq28fMOHPx7lbxsO4ubiQuiYrkzo43/toSSCg3Xhr5QqlIZBJXTgRBrTlobza0IqQzo14bV7u9K8vg4loZS6cRoGlUhWbh4Lvo/h3c2HqV/HjXcm9OSubs11KAmlVKlpGFQSe+LOMG1ZBDEp5xnb04eZd3XGy6Oms8tSSlURGgYV3IWsXP667iCL/xtLi/p1+PiRPgzq0MTZZSmlqhgNgwrsh0MnmbE8guOpF5l0UwB/GtYBz1r6K1NKlT1dslRAZy9k89o3+1j+cyJtGnuwdMpN9G7p7eyylFJVmIZBBWKM4ZuIJGatiuJcRg7P3t6Wp29vS60ars4uTSlVxZXqauciEisiESKyV0R2W23eIrJBRKKtWy+rXURkvojEiEi4iPSye55JVv9oEZlUurdUOZ1IzeSJT/bwzGe/0KJBHVb//mZeGNpBg0Ap5RBlsWYw2Bhzyu7xdOA7Y8wcEZluPZ4GjADaWT/9gIVAPxHxBl4GggAD7BGRVcaYs2VQW4WXn29YsusYr6/ZT05+PiEjO/HIwIDLh5JQSqlyVh6biUYDg6z7i4HN2MJgNPCJMcYA20WkgYg0t/puMMacARCRDcBw4PNyqK1COXrqAtOXhbPj6Bluat2QOeMCadmwkKEklFKqnJU2DAywXkQM8E9jzCKgqTEmyZp+Amhq3fcBjtnNm2C1FdV+FRGZDEwG8K/Eo23m5uXzrx+P8taGQ9Ss4cLccYE8EOSnJ48ppZymtGFwszEmUUSaABtE5ID9RGOMsYKiTFhhswggKCiozJ7XkaKOpzJtWTiRiWkM7dyU1+7tStN6tZ1dllKqmitVGBhjEq3bFBFZAfQFkkWkuTEmydoMlGJ1TwT87Gb3tdoS+d9mpYL2zaWpqyLKzMnjne+jee+HI3i51+Td4F6M6NpM1waUUhXCDe+lFBEPEalbcB8YCkQCq4CCI4ImASut+6uAidZRRf2BVGtz0jpgqIh4WUceDbXaqoxdsWcYOX8rCzYdZkxPHza+cCsjA3VMIaVUxVGaNYOmwAprgVYD+MwY862I7AK+FJHHgDjgAav/GmAkEANkAI8AGGPOiMhrwC6r36sFO5Mru/TMHN749iCfbo/D16sOnzzal1vbN3Z2WUopdRWxHdxT+QQFBZndu3c7u4wibTqQQsiKCJLSMnlkQCv+OLQ9HjqUhFLKyURkjzEm6Mp2XTqVsTMXsnl1dRRf7T1O+6aeLAseQC9/L2eXpZRS16RnNl2PsDAICAAXF9ttWNilScYYVu5NZMi8H/gmIonnhrTj69/fokGglKoUdM2gpMLCLr+gfFyc7TFwfNRYXvoqku8PpNDDrwFv3NeN9k3rOrFYpZS6PhoGJRUS8r8gsORnXCTso2+Ze6gRefmGmXd15uEBAbhe6zrESilVAWkYlFR8/GUPj3i1YPqIZ9np15Wb/Rrw+thA/LzdnVScUkqVjoZBSfn7Q1wcOS6uvN9nDG/f/CC1c7P5645Pue/1z/WcAaVUpaY7kEsqNJTIll0YPXEebwx6mCExO9kY9jz3P363BoFSqtLTNYMSyMzJ423v3rw/fg7eF9N4b0Uow7OOw9t/heBgZ5enlFKlpmFQjB1HTjN9eQRHT13gN0H+zBjZifp/f9DZZSmlVJnSMChCemYOc9YeIGxHPP7e7oQ93o+BbRs5uyyllCoXGgaF2LgvmZe+iiQlPZMnbmnFC3d2oE5NvfykUqrq0jCwc+p8Fq+s3sfqX4/TsVld/vlQb7r7NXB2WUopVe40DLANJfHV3kReXb2PC1l5vHBne6bc1oaaNfRgK6VU9VDtwyDx3EVCVkSw+eBJevk3YO64brTToSSUUtVMtQ2D/HzDv3fEMXftAQww6+7OPHSTDiWhlKqeqlcYhIVBSAgx5/OZPvpP7G7chlvbN+b/xnTF10uHklBKVV/VZ6N4WBi5T07hHy36MfLh+cR4Nmbe+ndYXDNag0ApVe1VnzWDkBBcL5xnW8vuDI3+Ly9vXETjjHPw0gH4rZ5FrJSq3qpPGMTHI8CHS1+lTm7WZe1KKVXdVZ/NRP7+AJcHgV27UkpVZ9UnDEJDwf2KfQPu7rZ2pZSq5qpPGAQHw6JF0LIliNhuFy3SUUeVUorqtM8AbAt+XfgrpdRVqs+agVJKqSJpGCillNIwUEoppWGglFIKDQOllFKAGGOcXcMNEZGTQJyz6yhCI+CUs4u4Bq2vdLS+0tH6Sqe09bU0xjS+srHShkFFJiK7jTFBzq6jKFpf6Wh9paP1lU551aebiZRSSmkYKKWU0jAoL4ucXUAxtL7S0fpKR+srnXKpT/cZKKWU0jUDpZRSGgZKKaXQMLhhIuInIptEZJ+IRInIHwrpM0hEUkVkr/XzFwfXGCsiEdZr7y5kuojIfBGJEZFwEenlwNo62H0ue0UkTUSeu6KPQz8/EflQRFJEJNKuzVtENohItHXrVcS8k6w+0SIyyYH1/VVEDli/vxUi0qCIea/5XSjH+maJSKLd73BkEfMOF5GD1ndxugPr+8KutlgR2VvEvI74/ApdpjjsO2iM0Z8b+AGaA72s+3WBQ0DnK/oMAr52Yo2xQKNrTB8JrAUE6A/scFKdrsAJbCfDOO3zA24FegGRdm1vANOt+9OBuYXM5w0csW69rPteDqpvKFDDuj+3sPpK8l0ox/pmAX8qwe//MNAaqAn8euXfUnnVd8X0vwF/ceLnV+gyxVHfQV0zuEHGmCRjzM/W/XRgP+Dj3Kqu22jgE2OzHWggIs2dUMcdwGFjjFPPKDfGbAHOXNE8Glhs3V8M3FvIrMOADcaYM8aYs8AGYLgj6jPGrDfG5FoPtwO+Zf26JVXE51cSfYEYY8wRY0w2sATb516mrlWfiAjwAPB5Wb9uSV1jmeKQ76CGQRkQkQCgJ7CjkMk3icivIrJWRLo4tDAwwHoR2SMikwuZ7gMcs3ucgHMCbTxF/xE68/MDaGqMSbLunwCaFtKnonyOj2Jb0ytMcd+F8vSMtRnrwyI2cVSEz+8WINkYE13EdId+flcsUxzyHdQwKCUR8QSWAc8ZY9KumPwztk0f3YF3gK8cXN7NxphewAjgaRG51cGvXywRqQncA/ynkMnO/vwuY2zr4xXyWGwRCQFygbAiujjru7AQaAP0AJKwbYqpiCZw7bUCh31+11qmlOd3UMOgFETEDdsvLcwYs/zK6caYNGPMeev+GsBNRBo5qj5jTKJ1mwKswLY6bi8R8LN77Gu1OdII4GdjTPKVE5z9+VmSCzadWbcphfRx6ucoIg8DdwHB1sLiKiX4LpQLY0yyMSbPGJMPvF/E6zr786sBjAW+KKqPoz6/IpYpDvkOahjcIGsb4wfAfmPMvCL6NLP6ISJ9sX3epx1Un4eI1C24j21HY+QV3VYBE62jivoDqXaro45S5H9kzvz87KwCCo7MmASsLKTPOmCoiHhZm0GGWm3lTkSGA1OBe4wxGUX0Kcl3obzqs98HNaaI190FtBORVtaa4nhsn7ujDAEOGGMSCpvoqM/vGssUx3wHy3PveFX+AW7GtroWDuy1fkYCU4ApVp9ngChsR0dsBwY4sL7W1uv+atUQYrXb1yfAAmxHckQAQQ7+DD2wLdzr27U57fPDFkpJQA62ba6PAQ2B74BoYCPgbfUNAv5lN++jQIz184gD64vBtq244Dv4ntW3BbDmWt8FB9X3qfXdCse2UGt+ZX3W45HYjp457Mj6rPaPC75zdn2d8fkVtUxxyHdQh6NQSimlm4mUUkppGCillELDQCmlFBoGSiml0DBQSimFhoFSSik0DJRSSgH/D5eqgYG4LCK2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Testing loss= 219194.843750000\n",
            "Absolute mean square loss difference: 211945.750000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54_Tj-BIaDPU"
      },
      "source": [
        "### Linear Regression using PyTorch built-ins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUrcVErtayVN"
      },
      "source": [
        "Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DwoqFKbaiSY"
      },
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# training data: this time we use 2d array\n",
        "# Assuming we have 90 samples of 10 features about a house condition, such as bedroom number, distance to city center etc.\n",
        "# and will predict the house price \n",
        "x_data = torch.randn(90, 10)\n",
        "y_data = torch.randn(90, 1)\n",
        "\n",
        "# testing data:\n",
        "x_test_data = torch.randn(10, 10)\n",
        "y_test_data = torch.randn(10, 1)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79_tCTbKa_Go"
      },
      "source": [
        "This time we don't need to initialize the weight and bias manually. Instead, we will define the model using the built-in [torch.nn.Linear](https://pytorch.org/docs/stable/nn.html#linear).\n",
        "\n",
        "[**torch.nn**](https://pytorch.org/docs/stable/nn.html) is a subpackage that contains modules and extensible classes for us to build neural networks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA8sqMF_bOSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4fe8610-59d9-4039-c69e-71a97196aa0c"
      },
      "source": [
        "# Define model\n",
        "linearRegression =  nn.Linear(10,1)\n",
        "print(linearRegression.weight)\n",
        "print(linearRegression.bias)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0140,  0.1093,  0.1096,  0.2873,  0.2761, -0.2000, -0.1113,  0.0535,\n",
            "         -0.1868,  0.2882]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0787], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4UxFi0bbeC3"
      },
      "source": [
        "Similarly, we don't manually updating the weight and bias using gradients by ourselves. Instead, we will use the optimizer optim.SGD.\n",
        "\n",
        "[**torch.optim**](https://pytorch.org/docs/stable/optim.html) is a subpackage that contains the standard optimization operations like Adam and SGD.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k62ayy77bu5W"
      },
      "source": [
        "# Define optimizer\n",
        "# Just pass the model parameters to be updated and specify the learning rate when calling optim.SGD\n",
        "# SGD optimizer in PyTorch actually is Mini-batch Gradient Descent with momentum.\n",
        "# In this case, as the batch size of our model is N, SGD here is actually Batch Gradient Descent.\n",
        "optimizer = torch.optim.SGD(linearRegression.parameters(), lr=1e-5)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfKM513UcH-4"
      },
      "source": [
        "Again, we use the built-in loss function mse_loss instead of defining it manually.\n",
        "\n",
        "We will need the [**torch.nn.functional**](https://pytorch.org/docs/stable/nn.functional.html) interface, which contains typical operations used for building neural networks such as convolution operations, activation functions and loss functions we need here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKWCYuiocOUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1b3bf6-3c8e-4695-97f1-1d60aeb23333"
      },
      "source": [
        "# Import nn.functional \n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the loss function\n",
        "loss_func = F.mse_loss\n",
        "\n",
        "# Calculate loss\n",
        "loss = loss_func(linearRegression(x_data), y_data)\n",
        "print(loss)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.6187, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1pjqzZCNJgJ"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbYtLruwwRfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575bac36-d54d-46df-e138-0da085a82963"
      },
      "source": [
        "# An epoch is one iteration over the entire input data\n",
        "no_of_epochs = 5000\n",
        "# How often you want to display training info.\n",
        "display_interval = 200\n",
        "\n",
        "for epoch in range(no_of_epochs):\n",
        "  predictions = linearRegression(x_data)\n",
        "  loss = loss_func(predictions, y_data)\n",
        "  loss.backward()\n",
        "  optimizer.step() #call step() to automatically update the parameters through our defined optimizer, which can be called once after backward()\n",
        "  optimizer.zero_grad() #reset the gradient as what we did before\n",
        "  if epoch % display_interval == 0 :\n",
        "      # calculate the cost of the current model\n",
        "      predictions = linearRegression(x_data)\n",
        "      loss = loss_func(predictions, y_data)          \n",
        "      print(\"Epoch:\", '%04d' % (epoch), \"loss=\", \"{:.8f}\".format(loss))\n",
        "\n",
        "print(\"=========================================================\")\n",
        "training_loss = mse(linearRegression(x_data), y_data)   \n",
        "print(\"Optimised:\", \"loss=\", \"{:.9f}\".format(training_loss.data))\n",
        "\n",
        "\n",
        "# Calculate testing loss\n",
        "testing_loss = loss_func(linearRegression(x_test_data), y_test_data) \n",
        "print(\"Testing loss=\", \"{:.9f}\".format(testing_loss.data))\n",
        "print(\"Absolute mean square loss difference:\", \"{:.9f}\".format(abs(\n",
        "      training_loss.data - testing_loss.data)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0000 loss= 1.61863160\n",
            "Epoch: 0200 loss= 1.61439383\n",
            "Epoch: 0400 loss= 1.61019409\n",
            "Epoch: 0600 loss= 1.60603285\n",
            "Epoch: 0800 loss= 1.60190976\n",
            "Epoch: 1000 loss= 1.59782517\n",
            "Epoch: 1200 loss= 1.59377718\n",
            "Epoch: 1400 loss= 1.58976698\n",
            "Epoch: 1600 loss= 1.58579302\n",
            "Epoch: 1800 loss= 1.58185470\n",
            "Epoch: 2000 loss= 1.57795322\n",
            "Epoch: 2200 loss= 1.57408655\n",
            "Epoch: 2400 loss= 1.57025576\n",
            "Epoch: 2600 loss= 1.56646001\n",
            "Epoch: 2800 loss= 1.56269836\n",
            "Epoch: 3000 loss= 1.55897081\n",
            "Epoch: 3200 loss= 1.55527711\n",
            "Epoch: 3400 loss= 1.55161643\n",
            "Epoch: 3600 loss= 1.54799020\n",
            "Epoch: 3800 loss= 1.54439652\n",
            "Epoch: 4000 loss= 1.54083455\n",
            "Epoch: 4200 loss= 1.53730571\n",
            "Epoch: 4400 loss= 1.53380752\n",
            "Epoch: 4600 loss= 1.53034198\n",
            "Epoch: 4800 loss= 1.52690756\n",
            "=========================================================\n",
            "Optimised: loss= 1.523521066\n",
            "Testing loss= 0.827727914\n",
            "Absolute mean square loss difference: 0.695793152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g3eNemEOklg"
      },
      "source": [
        "# NLTK Library and WordNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8btJKEBxSS1"
      },
      "source": [
        "WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofWRw7omOeWf"
      },
      "source": [
        "In Python, NLTK library includes English WordNet.\n",
        "\n",
        "**To use wordnet, you need to download the wordnet data via NLTK library**\n",
        "\n",
        " * **[NLTK](https://www.nltk.org/)** is a **N**atural **L**anguage **T**ool**k**iit for python. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVqxuaIpOIOl"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2cusD7IovCi"
      },
      "source": [
        "## WordNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuDwzN6OosjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383a9f9f-1e94-4599-8b5e-9a69851c733f"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JKvb0XKNzxw"
      },
      "source": [
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucVb1XeAnnFo"
      },
      "source": [
        "Let's get a set of synonyms that share a common meaning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecoLLQPlxlOc"
      },
      "source": [
        "dog = wn.synset('dog.n.01')\n",
        "person = wn.synset('person.n.01')\n",
        "cat = wn.synset('cat.n.01')\n",
        "computer = wn.synset('computer.n.01')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4rd7JPrr4sc"
      },
      "source": [
        "### path_similarity()\n",
        "path_similarity() returns a score denoting how similar two word senses are, based on the shortest path that connects the senses in the is-a (hypernym/hypnoym) taxonomy. The score is in the range 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiTFSsHqsREt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1af527a-4abd-4899-ba4e-ccd4df5e56af"
      },
      "source": [
        "print(\"dog<->cat : \", wn.path_similarity(dog,cat))\n",
        "print(\"person<->cat : \", wn.path_similarity(person,cat))\n",
        "print(\"person<->dog : \", wn.path_similarity(person,dog))\n",
        "print(\"person<->computer : \", wn.path_similarity(person,computer))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog<->cat :  0.2\n",
            "person<->cat :  0.1\n",
            "person<->dog :  0.2\n",
            "person<->computer :  0.1111111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJfYbAtPrMNS"
      },
      "source": [
        "### Wu-Palmer Similarity (wup_similarity() )\n",
        "wup_similarity() returns a score denoting how similar two word senses are, based on the depth of the two senses in the taxonomy and that of their Least Common Subsumer (most specific ancestor node)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jno6d9Mdrbu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e08af03-e1f3-414c-c85e-6ea52709df96"
      },
      "source": [
        "print(\"dog<->cat : \", wn.wup_similarity(dog,cat))\n",
        "print(\"person<->cat : \", wn.wup_similarity(person,cat))\n",
        "print(\"person<->dog : \", wn.wup_similarity(person,dog))\n",
        "print(\"person<->computer : \", wn.wup_similarity(person,computer))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog<->cat :  0.8571428571428571\n",
            "person<->cat :  0.5714285714285714\n",
            "person<->dog :  0.75\n",
            "person<->computer :  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVtVC7LnqS9T"
      },
      "source": [
        "# TFIDF (Term Frequency Inverse Document Frequency)\n",
        "\n",
        "TFIDF is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.\n",
        "\n",
        "\n",
        "**Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcjJPxPIHsVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64e2dd1-4b92-4114-80a0-72def0844634"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "\n",
        "corpus = [\n",
        "    'Caren loves the NLP. The NLP hates Caren', #document 1\n",
        "    'Caren hates the NLP' #document 2\n",
        "]\n",
        "\n",
        "# Tokenize sentences - for only doc1\n",
        "tokenized_sentence = sent_tokenize(corpus[0])\n",
        "print(\"\\ntokenized_sentence: \")\n",
        "print(tokenized_sentence)\n",
        "\n",
        "# Remove punctuations - for only doc1\n",
        "clean_doc1 = re.sub(r'[^\\w\\s]','',corpus[0])\n",
        "print(\"\\nclean_sentence: \")\n",
        "print(clean_doc1)\n",
        "\n",
        "# Tokenize words - for only doc1\n",
        "tokenized_doc1 = word_tokenize(clean_doc1)\n",
        "print(\"\\ntokenized_word: \")\n",
        "print(tokenized_doc1)\n",
        "\n",
        "# Convert the tokens into lowercase: lower_tokens\n",
        "lower_tokens = [t.lower() for t in tokenized_doc1]\n",
        "print(\"\\nlower_case: \")\n",
        "print(lower_tokens)\n",
        "\n",
        "# stop word removal\n",
        "sww = sw.words()\n",
        "tokenized_doc1 = [w for w in lower_tokens if not w in sww]\n",
        "print(\"\\ntokensized_word (in lower case, w/o stopwords): \")\n",
        "print(tokenized_doc1)\n",
        "\n",
        "# same process for doc2\n",
        "clean_doc2 = re.sub(r'[^\\w\\s]','',corpus[1])\n",
        "tokenized_doc2 = word_tokenize(clean_doc2)\n",
        "lower_tokens2 = [t.lower() for t in tokenized_doc2]\n",
        "tokenized_doc2 = [w for w in lower_tokens2 if not w in sww]\n",
        "\n",
        "tokensized_docs = [tokenized_doc1, tokenized_doc2]\n",
        "print(\"\\nfinal_docs: \")\n",
        "print(tokensized_docs[0])\n",
        "print(tokensized_docs[1])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "\n",
            "tokenized_sentence: \n",
            "['Caren loves the NLP.', 'The NLP hates Caren']\n",
            "\n",
            "clean_sentence: \n",
            "Caren loves the NLP The NLP hates Caren\n",
            "\n",
            "tokenized_word: \n",
            "['Caren', 'loves', 'the', 'NLP', 'The', 'NLP', 'hates', 'Caren']\n",
            "\n",
            "lower_case: \n",
            "['caren', 'loves', 'the', 'nlp', 'the', 'nlp', 'hates', 'caren']\n",
            "\n",
            "tokensized_word (in lower case, w/o stopwords): \n",
            "['caren', 'loves', 'nlp', 'nlp', 'hates', 'caren']\n",
            "\n",
            "final_docs: \n",
            "['caren', 'loves', 'nlp', 'nlp', 'hates', 'caren']\n",
            "['caren', 'hates', 'nlp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSeX6VnhTeA5"
      },
      "source": [
        "**Document Frequency (DF)**\n",
        "\n",
        "DF is the count of occurrences of term t in the document set N\n",
        "\n",
        "*df(t) = occurrence of t in documents*\n",
        "\n",
        "*idf(t) = log(N/(df + 1))*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEOTCuiZTdl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996719c1-c06e-4528-e796-260d6bf6b260"
      },
      "source": [
        "DF = {}\n",
        "\n",
        "for tokensized_doc in tokensized_docs:\n",
        "    # get each unique word in the doc - and count the number of occurrences in the document\n",
        "    for term in np.unique(tokensized_doc):\n",
        "        try:\n",
        "            DF[term] +=1\n",
        "        except:\n",
        "            DF[term] =1\n",
        "\n",
        "DF"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'caren': 2, 'hates': 2, 'loves': 1, 'nlp': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6s15-FpdhrM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32df30df-a40b-41b5-8308-082d316f44b6"
      },
      "source": [
        "DF['caren']"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEpq2ws8Lsos"
      },
      "source": [
        "**TF-IDF calculation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9QHJ8gA1iMO"
      },
      "source": [
        "In the following sample code, we will use [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) to easily count the word occurance in a document. [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) is a Python class that enables counting for elements from an iterable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNeraCvfIO3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc844fca-b3c0-40e7-e38c-8219a40a87f0"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "\n",
        "tf_idf = {}\n",
        "\n",
        "# total number of documents\n",
        "N = len(tokensized_docs) \n",
        "\n",
        "doc_id = 0\n",
        "# get each tokenised doc\n",
        "for tokensized_doc in tokensized_docs:\n",
        "    # initialise counter for the doc\n",
        "    counter = Counter(tokensized_doc)\n",
        "    # calculate total number of words in the doc\n",
        "    total_num_words = len(tokensized_doc)    \n",
        "\n",
        "    # get each unique word in the doc\n",
        "    for term in np.unique(tokensized_doc):\n",
        "\n",
        "        # calculate Term Frequency \n",
        "        tf = counter[term]/total_num_words\n",
        "        \n",
        "        # calculate Document Frequency\n",
        "        df = DF[term]\n",
        "\n",
        "        # calculate Inverse Document Frequency\n",
        "        idf = math.log(N/(df+1))+1\n",
        "\n",
        "        # calculate TF-IDF\n",
        "        tf_idf[doc_id, term] = tf*idf\n",
        "\n",
        "    doc_id += 1\n",
        "\n",
        "tf_idf"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 'caren'): 0.19817829729727854,\n",
              " (0, 'hates'): 0.09908914864863927,\n",
              " (0, 'loves'): 0.16666666666666666,\n",
              " (0, 'nlp'): 0.19817829729727854,\n",
              " (1, 'caren'): 0.19817829729727854,\n",
              " (1, 'hates'): 0.19817829729727854,\n",
              " (1, 'nlp'): 0.19817829729727854}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tETfBpygMC-u"
      },
      "source": [
        "**Sort by the importance - Descending Order**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAB7bU-15uK1"
      },
      "source": [
        "We use Python built-in function [sorted](https://docs.python.org/3/howto/sorting.html) for sorting the words based on its tf_idf values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R4BI1-UH35-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549ea644-0a1e-40a3-b5b2-e54c2a3fb196"
      },
      "source": [
        "import numpy as np\n",
        "#sort the dictionary based on values\n",
        "dict_exmaple = tf_idf\n",
        "sorted_dict = sorted(dict_exmaple.items(), key=lambda x: x[1], reverse=True)\n",
        "sorted_dict"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((0, 'caren'), 0.19817829729727854),\n",
              " ((0, 'nlp'), 0.19817829729727854),\n",
              " ((1, 'caren'), 0.19817829729727854),\n",
              " ((1, 'hates'), 0.19817829729727854),\n",
              " ((1, 'nlp'), 0.19817829729727854),\n",
              " ((0, 'loves'), 0.16666666666666666),\n",
              " ((0, 'hates'), 0.09908914864863927)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqD22EW5PZRa"
      },
      "source": [
        "# Exercise\n",
        "Please complete the following **two questions** E1 and E2 and you should submit **\"ipynb\" file to Canvas** (You can download it from \"File\" > \"Download .ipynb\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF-vRmAYVpMk"
      },
      "source": [
        "##E1. What are the advantages of using TF-IDF over TF (Term Frequency)?\r\n",
        "Please write down your answer below with a **supportive example**, using your own words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jMj_HobwXgR8"
      },
      "source": [
        "#@Lab01 - E1\r\n",
        "\r\n",
        "Answer = \" Type in here \" #@param {type:\"raw\"}"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wda8pzFGy4LS"
      },
      "source": [
        "## E2. Write a function which returns the top N (e.g. 10 or 20) words with the largest TF value and with the largest TF-IDF values for a paragraph of corpus (Wikipedia page)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zqy-jz_zJKR"
      },
      "source": [
        "In thise exercise, we will simply use the documents by using the [wikipedia library](https://pypi.org/project/wikipedia/), which is a Python library that makes it easy to access and parse data from Wikipedia. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAd2bqFR3CfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360414c8-0851-4e11-8f5b-ddc10bba9c14"
      },
      "source": [
        "# Install and import the wikipedia library\n",
        "!pip install wikipedia\n",
        "import wikipedia"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JSYTirTx6ML"
      },
      "source": [
        "# Let's collect the page content from the following COVID-19 related wiki pages as documents\n",
        "# by using wikipedia.page(COVID).content, which returns a list of COVID-19 related documents \n",
        "COVID_docs = [\"COVID-19_pandemic\", \"Coronavirus_disease_2019\", \"Long_COVID\"]\n",
        "documents = [wikipedia.page(COVID).content for COVID in COVID_docs]\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi73fUXy1pC7",
        "outputId": "884adeb7-8825-4e07-cabe-a7fbf0ff333c"
      },
      "source": [
        "tokensized_docs = []\n",
        "\n",
        "# Preprocessing\n",
        "for document in documents:\n",
        "  # Remove punctuations\n",
        "  clean_doc = re.sub(r'[^\\w\\s]','',document)\n",
        "  # Tokenize words\n",
        "  tokenized_doc = word_tokenize(clean_doc)\n",
        "  # Convert the tokens into lowercase: lower_tokens\n",
        "  lower_tokens = [t.lower() for t in tokenized_doc]\n",
        "  # stop word removal\n",
        "  tokenized_doc = [w for w in lower_tokens if not w in sw.words()]\n",
        "  # add tokenized doc to new list\n",
        "  tokensized_docs.append(tokenized_doc)\n",
        "\n",
        "print(len(tokensized_docs))\n",
        "\n",
        "DF = {}\n",
        "for tokensized_doc in tokensized_docs:\n",
        "    # get each unique word in the doc - and count the number of occurrences in the document\n",
        "    for term in np.unique(tokensized_doc):\n",
        "        try:\n",
        "            DF[term] +=1\n",
        "        except:\n",
        "            DF[term] =1\n",
        "tf_idf = {}\n",
        "tf_dict = {}\n",
        "\n",
        "# total number of documents\n",
        "N = len(tokensized_docs) \n",
        "\n",
        "doc_id = 0\n",
        "# get each tokenised doc\n",
        "for tokensized_doc in tokensized_docs:\n",
        "    # initialise counter for the doc\n",
        "    counter = Counter(tokensized_doc)\n",
        "    # calculate total number of words in the doc\n",
        "    total_num_words = len(tokensized_doc)    \n",
        "\n",
        "    # get each unique word in the doc\n",
        "    for term in np.unique(tokensized_doc):\n",
        "\n",
        "        # calculate Term Frequency \n",
        "        tf = counter[term]/total_num_words\n",
        "        tf_dict[doc_id, term] = tf\n",
        "        \n",
        "        # calculate Document Frequency\n",
        "        df = DF[term]\n",
        "\n",
        "        # calculate Inverse Document Frequency\n",
        "        idf = math.log(N/(df+1))+1\n",
        "\n",
        "        # calculate TF-IDF\n",
        "        tf_idf[doc_id, term] = tf*idf\n",
        "\n",
        "    doc_id += 1\n",
        "\n",
        "#sort the dictionary based on values\n",
        "sorted_tfidf = sorted(tf_idf.items(), key=lambda x: x[1], reverse=True)\n",
        "sorted_tf = sorted(tf_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "top = 10\n",
        "print(\"Top {} Term Frequency Inverse Document Frequency\". format(top))\n",
        "for term in sorted_tfidf[:top]:\n",
        "  print(term)\n",
        "print(\"Top {} Term Frequency\". format(top))\n",
        "for term in sorted_tf[:top]:\n",
        "  print(term)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 Term Frequency Inverse Document Frequency\n",
            "((2, 'covid'), 0.027225901398086828)\n",
            "((2, 'symptoms'), 0.01939349765951737)\n",
            "((2, 'long'), 0.016772754732555562)\n",
            "((1, 'covid19'), 0.014203390311366968)\n",
            "((0, '2020'), 0.01016628821429428)\n",
            "((0, 'covid19'), 0.00939171387415757)\n",
            "((2, 'covid19'), 0.008910525951670144)\n",
            "((2, 'people'), 0.008910525951670144)\n",
            "((2, 'infection'), 0.008386377366277781)\n",
            "((0, 'cases'), 0.008326674156469599)\n",
            "Top 10 Term Frequency\n",
            "((2, 'covid'), 0.027225901398086828)\n",
            "((2, 'symptoms'), 0.027225901398086828)\n",
            "((2, 'long'), 0.0235467255334805)\n",
            "((1, 'covid19'), 0.019939678284182305)\n",
            "((0, '2020'), 0.014272121788772598)\n",
            "((0, 'covid19'), 0.013184722033437542)\n",
            "((2, 'covid19'), 0.012509197939661517)\n",
            "((2, 'people'), 0.012509197939661517)\n",
            "((2, 'infection'), 0.01177336276674025)\n",
            "((0, 'cases'), 0.011689547369851842)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTE6EjOF_TBx"
      },
      "source": [
        "### Complete this section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r3bS9yT2Z2k"
      },
      "source": [
        "\r\n",
        "Please fill in the following functions with code body: \r\n",
        "\r\n",
        "Pass both the (list of) documents and the number of (top) words to focus into the function.\r\n",
        "\r\n",
        "In the function, you may:\r\n",
        "  \r\n",
        "*   process the documents (e.g. tokenization) - provided in the sample code above. **Please add two additional stop words: covid19 and covid.**\r\n",
        "*   calculate the tf/tfidf values for each unique words ([Counter](https://docs.python.org/3/library/collections.html#collections.Counter) can be a one of the good choices)\r\n",
        "*   sorting the words based on the tf/tfidf values (Using Python built-in function [sorted](https://docs.python.org/3/howto/sorting.html) might be helpful for sorting)\r\n",
        "*   print out the top n tf words tfidf words from the sorted list in parallel for comparison\r\n",
        "\r\n",
        "In your final submission, the print log should be kept in the cell execution output field. Note that you can write extra functions if you need, but do remember to include the functions in this section for final submission.\r\n",
        "\r\n",
        "  \r\n",
        "  \r\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7urSTB005hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859e312a-04b8-4ecd-8bb6-f935b347e5c0"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "from nltk.corpus import stopwords as sw\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from collections import Counter\r\n",
        "import math\r\n",
        "\r\n",
        "def get_tokenised_documents(documents, additionalStopWords=[]):\r\n",
        "  # intialise list to store tokenized corpus\r\n",
        "  tokenized_documents = []\r\n",
        "  for document in documents:\r\n",
        "    # Remove punctuations\r\n",
        "    clean_doc = re.sub(r'[^\\w\\s]','',document)\r\n",
        "    # Tokenize words\r\n",
        "    tokenized_doc = word_tokenize(clean_doc)\r\n",
        "    # Convert the tokens into lowercase: lower_tokens\r\n",
        "    lower_tokens = [t.lower() for t in tokenized_doc]\r\n",
        "    # stop word removal\r\n",
        "    stopwords = sw.words()\r\n",
        "    # add any additional stop words\r\n",
        "    stopwords.extend(additionalStopWords)\r\n",
        "    tokenized_doc = [w for w in lower_tokens if not w in stopwords]\r\n",
        "    # add tokenized doc to new list\r\n",
        "    tokenized_documents.append(tokenized_doc)\r\n",
        "  return tokenized_documents\r\n",
        "\r\n",
        "def get_document_freq(tokenized_docs):\r\n",
        "  DF = {}\r\n",
        "  for tokensized_doc in tokenized_docs:\r\n",
        "      # get each unique word in the doc - and count the number of occurrences in the document\r\n",
        "      for term in np.unique(tokensized_doc):\r\n",
        "          try:\r\n",
        "              DF[term] +=1\r\n",
        "          except:\r\n",
        "              DF[term] =1\r\n",
        "  return DF\r\n",
        "\r\n",
        "def get_tf_and_idf(corpus, top_n):\r\n",
        "  ## Write your code body here\r\n",
        "  # process the document (** add covid19 and covid as two additional stop words)\r\n",
        "  additionalStopWords = [\"covid19\", \"covid\"]\r\n",
        "  tokenized_documents = get_tokenised_documents(corpus, additionalStopWords)\r\n",
        "\r\n",
        "  # calculate the tf/tfidf values for each unique words\r\n",
        "  # get document frequency first in order to calculate tf-idf\r\n",
        "  DF = get_document_freq(tokenized_documents)\r\n",
        "  \r\n",
        "  # initilaise dicitonary to store tf and tf-idf\r\n",
        "  tf_idf = {}\r\n",
        "  tf_dict = {}\r\n",
        "\r\n",
        "  # total number of documents\r\n",
        "  N = len(tokenized_documents)\r\n",
        "  doc_id = 0\r\n",
        "  # get each tokenised doc\r\n",
        "  for tokensized_doc in tokenized_documents:\r\n",
        "      # initialise counter for the doc\r\n",
        "      counter = Counter(tokensized_doc)\r\n",
        "      # calculate total number of words in the doc\r\n",
        "      total_num_words = len(tokensized_doc)    \r\n",
        "      # get each unique word in the doc\r\n",
        "      for term in np.unique(tokensized_doc):\r\n",
        "          # calculate Term Frequency \r\n",
        "          tf = counter[term]/total_num_words\r\n",
        "          # apped term frequency to document\r\n",
        "          tf_dict[doc_id, term] = tf\r\n",
        "          # get Document Frequency\r\n",
        "          df = DF[term]\r\n",
        "          # calculate Inverse Document Frequency\r\n",
        "          idf = math.log(N/(df+1))+1\r\n",
        "          # calculate TF-IDF and appened\r\n",
        "          tf_idf[doc_id, term] = tf*idf\r\n",
        "      doc_id += 1\r\n",
        "\r\n",
        "  # sorting the words based on the tf/tfidf valuse\r\n",
        "  sorted_tfidf = sorted(tf_idf.items(), key=lambda x: x[1], reverse=True)\r\n",
        "  sorted_tf = sorted(tf_dict.items(), key=lambda x: x[1], reverse=True)\r\n",
        "\r\n",
        "  # print out the top n tf words and top n tfidf words from the sorted list in parallel for comparision\r\n",
        "  print(\"Top {} TF and TF-IDF\".format(top_n))\r\n",
        "  for tf, tfidf in zip(sorted_tf[:top_n], sorted_tfidf[:top_n]):\r\n",
        "    print(tf, tfidf)\r\n",
        "\r\n",
        "# Call the funtion, the execution print out log should be kept for submission\r\n",
        "get_tf_and_idf(corpus, 10)\r\n",
        "get_tf_and_idf(documents, 10)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 TF and TF-IDF\n",
            "((0, 'caren'), 0.3333333333333333) ((0, 'caren'), 0.19817829729727854)\n",
            "((0, 'nlp'), 0.3333333333333333) ((0, 'nlp'), 0.19817829729727854)\n",
            "((1, 'caren'), 0.3333333333333333) ((1, 'caren'), 0.19817829729727854)\n",
            "((1, 'hates'), 0.3333333333333333) ((1, 'hates'), 0.19817829729727854)\n",
            "((1, 'nlp'), 0.3333333333333333) ((1, 'nlp'), 0.19817829729727854)\n",
            "((0, 'hates'), 0.16666666666666666) ((0, 'loves'), 0.16666666666666666)\n",
            "((0, 'loves'), 0.16666666666666666) ((0, 'hates'), 0.09908914864863927)\n",
            "Top 10 TF and TF-IDF\n",
            "((2, 'symptoms'), 0.028352490421455937) ((2, 'symptoms'), 0.020195987217842225)\n",
            "((2, 'long'), 0.024521072796934867) ((2, 'long'), 0.017466799755971655)\n",
            "((0, '2020'), 0.014462809917355372) ((0, '2020'), 0.010302118786854409)\n",
            "((2, 'people'), 0.013026819923371647) ((2, 'people'), 0.009279237370359942)\n",
            "((2, 'infection'), 0.012260536398467433) ((2, 'infection'), 0.008733399877985827)\n",
            "((0, 'cases'), 0.011845730027548209) ((0, 'cases'), 0.008437925863518849)\n",
            "((1, 'virus'), 0.011114911080711354) ((1, 'virus'), 0.007917350425895048)\n",
            "((2, 'patients'), 0.010727969348659003) ((2, 'patients'), 0.007641724893237599)\n",
            "((2, '2020'), 0.00996168582375479) ((2, '2020'), 0.007095887400863486)\n",
            "((2, 'syndrome'), 0.00996168582375479) ((2, 'syndrome'), 0.007095887400863486)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0s42Gmq7yhe"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}